{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552bbe1d-d493-43ed-8dd1-1c70d9b098f7",
   "metadata": {},
   "source": [
    "## Introduction to _\"Spectral Audification\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293adae8-2bf9-4e06-a32c-5319601b31fa",
   "metadata": {},
   "source": [
    "### 0. Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3143e-b034-4c97-afa4-2de6b5b59104",
   "metadata": {},
   "source": [
    "First import a load of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6742b-50c2-45bc-90b7-d96cd60a27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from strauss.sonification import Sonification\n",
    "from strauss.sources import Events, Objects\n",
    "from strauss import channels\n",
    "from strauss.score import Score\n",
    "from strauss.generator import Spectralizer\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['figure.figsize'] = (6,1)\n",
    "# print(mpl.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf43f5-823e-41bc-9566-f666ff83f503",
   "metadata": {},
   "source": [
    "and initialise some _STRAUSS_ objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a3d5a-539c-4581-8ef8-96f4b8aeebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score =  Score([['A2']], 1)\n",
    "generator = Spectralizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9a8c8-8cae-44e6-a52f-4cf5c1d22887",
   "metadata": {},
   "source": [
    "...and set up a function to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2b32c-c3ad-4e69-9dbb-18ad289a78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec2sound(freq, spec, soni):\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(121)\n",
    "    plt.fill_between(freq,spec, alpha=0.4)\n",
    "    plt.plot(freq,spec)\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(122)\n",
    "    plt.plot(soni.out_channels['0'].values[:1200])\n",
    "    plt.axis('off')\n",
    "    arrow = patches.FancyArrowPatch(\n",
    "        (0.48,0.5),(0.52,0.5), shrinkA=0, shrinkB=0, \n",
    "        transform=fig.transFigure, color=\"C0\", arrowstyle=\"-|>\",\n",
    "        mutation_scale=15, linewidth=2)\n",
    "    fig.patches.append(arrow)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43d66f-6b63-472f-9aa5-a57a219d8591",
   "metadata": {},
   "source": [
    "### 1. The Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444d957-cd22-4cc9-b2fa-fefeb2376811",
   "metadata": {},
   "source": [
    "Here we'll explore some of the basic spectral features and how they manifest with the spectral audification approach used in the JDAViz Listener implementation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0be02-318c-4277-8f4c-29e0fd20de89",
   "metadata": {},
   "source": [
    "This approach is fundamentally based on an inverse Fourier transform, where the frequencies of light are mapped onto frequencies of sound.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115280c2-11fa-4a98-94a5-2accffa7e5b4",
   "metadata": {},
   "source": [
    "In this pardigm, delta functions become sinusoids of different frequencies, which are heard as tones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182945f-6204-4ca0-83d6-3dd5e8f28594",
   "metadata": {},
   "source": [
    "![image](images/intro_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce60041-6e4d-44d1-a521-a8a93c96f538",
   "metadata": {},
   "source": [
    "![image](images/intro_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d70cc-faab-4aa5-8435-8e1bccd3a125",
   "metadata": {},
   "source": [
    "These combine linearly and we hear something like a _\"chord\"_ which tells us about the combination of lines..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746faf03-46d0-4b02-8937-8dd8efb2e210",
   "metadata": {},
   "source": [
    "![image](images/intro_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17b870-7952-4c1c-aae9-6792049d7919",
   "metadata": {},
   "source": [
    "Other features, like the continuum manigest as 'spectral noise' - this is like many, many sinusoids playing at once. A constant-values continuum manifests in something like _\"white noise\"_ while sloped continuua can yield something _\"coloured noise\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058bc85-b370-40b6-8765-458fd8d6aa14",
   "metadata": {},
   "source": [
    "![image](images/intro_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885b278-c520-4404-b673-5a8c86384c15",
   "metadata": {},
   "source": [
    "### 2. Examples: Single Emission Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ebd9d-636c-42c6-ade4-81cfcb91b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pretend this is an astronomical spectrum, between 200 and 800 nm\n",
    "freqs = np.linspace(400, 750, 10000) # say, THz\n",
    "zspec = np.zeros(wavelength.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed691ad6-b804-45cf-ad41-61dea930b15d",
   "metadata": {},
   "source": [
    "Set single values to 1 to approximate a delta function at different frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fd999-228b-49e5-a876-99d74f1172f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec1 = zspec.copy()\n",
    "spec2 = zspec.copy()\n",
    "spec3 = zspec.copy()\n",
    "\n",
    "spec1[500] = 1\n",
    "spec2[spec.size//2] = 1\n",
    "spec3[-500] = 1\n",
    "\n",
    "specs = (spec1, spec2, spec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077150ad-3402-498f-9234-e2060e328387",
   "metadata": {},
   "source": [
    "...and let's hear them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4537ced-3939-49ff-9b65-1e1b3dd948d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pick the mapping frequency range for the spectrum...\n",
    "generator.modify_preset({'min_freq':100, 'max_freq':500})\n",
    "data = {'spectrum':[spec], 'pitch':[1]}\n",
    "lims = {'spectrum': (0,1)}\n",
    "\n",
    "for s in specs:\n",
    "    print('='*60)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "    \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839ce1d-d7c7-4dd7-8c0c-972335b8aeba",
   "metadata": {},
   "source": [
    "Hear how the low frequency line results in a lower potch representation and vice versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e0c4a8-01ae-437e-a83e-6ed21125998f",
   "metadata": {},
   "source": [
    "### 3. Examples: Continuua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b288d5f6-9ef0-49c6-aba5-323badd963de",
   "metadata": {},
   "source": [
    "Next, we show the effect of a continuum term..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778597ce-0abf-48c1-a897-8a3a561ed3d4",
   "metadata": {},
   "source": [
    "Just trying a negative sloped, constant, and positively sloped continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862776ee-9c3b-4a55-aded-d1cd0045f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linspec = np.linspace(0,1, 10000)\n",
    "\n",
    "spec4 = linspec**1\n",
    "spec5 = linspec**0\n",
    "spec6 = 1-linspec**1\n",
    "\n",
    "specs2 = (spec4, spec5, spec6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf468d-8d71-4097-b58a-e695bcdcbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.modify_preset({'min_freq':100, 'max_freq':5000})\n",
    "\n",
    "for s in specs2:\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "        \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef189a1b-4960-4591-bb76-688e789b2c4f",
   "metadata": {},
   "source": [
    "Hear the different timbres of these examples. I positively sloped continuum has more of a _'hiss'_ due to boosterd high-frequency power (_\"treble\"_) while the negative slope more of a _'rumble'_ due to low-frequency power (\"_bass_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929be9f4-774a-4a20-a825-6bf3b27b4b1d",
   "metadata": {},
   "source": [
    "### 4. Examples: Emission Line Widths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0a47c-1455-4778-a487-63a61932b1ab",
   "metadata": {},
   "source": [
    "Line profiles may not be in the narrow ($\\delta$-function-like) limit, so what is the effect of the relative line width on the sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91acc2c-211e-4e06-baae-495eccd38d96",
   "metadata": {},
   "source": [
    "Lets make some Gaussian profiles of varying width ($\\sigma$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c09dc-bd8d-4914-b919-95082c226072",
   "metadata": {},
   "outputs": [],
   "source": [
    "linspec = np.linspace(0,1,10000)\n",
    "std = 1e-3\n",
    "\n",
    "spec7 = np.exp(-((linspec-0.5)/std)**2)\n",
    "spec8 = np.exp(-((linspec-0.5)/(std*40))**2)\n",
    "spec9 = np.exp(-((linspec-0.5)/(std*80))**2)\n",
    "\n",
    "specs3 = (spec7, spec8, spec9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c485d-7bcb-44ff-9d1b-1e5e41e76645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator.modify_preset({'min_freq':100, 'max_freq':1000})\n",
    "\n",
    "for s in specs3:\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "        \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdac9a-4113-4102-b46e-9ac651f4f30a",
   "metadata": {},
   "source": [
    "The pure tone of a narrow line gives may to a more _\"intense\"_, _\"windy\"_ or _\"breathy\"_ sound. Note a wider line includes a broader range of frequencies and therefore a noisier sound.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee575b-b1ef-4353-b448-39b963e6c8b7",
   "metadata": {},
   "source": [
    "### 5. Examples: Absorption Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c229a9f-d957-4f9f-8b19-8bd2ffe8fc9e",
   "metadata": {},
   "source": [
    "But what about absorption? In this case the line is represent by an _absence_ of sound frequencies. This is generally a lot harder to identify - can you hear one missing frequency out of thousands playing, as opposed to one tone.\n",
    "\n",
    "Line widths can make this more noticable - but in general this is hard... an idea is to invert the absorption features so they become emission features and therefore more perceptible.\n",
    "\n",
    "Let's try different line-widths, including no line at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80ee92-27f2-4ef8-b67a-9fcc8fbae438",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs3 = (spec5, 1-spec7, 1-spec8, 1-spec9**0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b4c85-075b-4bff-97e3-798bf82af1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.modify_preset({'min_freq':100, 'max_freq':5000})\n",
    "\n",
    "for s in specs3:\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "        \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efda4e-4164-4001-8f06-01b5bbfc6607",
   "metadata": {},
   "source": [
    "Could you notice any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85877f1-f271-4763-9098-98f698d3fd79",
   "metadata": {},
   "source": [
    "### 6. Examples: Emission Lines + Continuum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4e532-2194-4dc2-8743-37cf9072034f",
   "metadata": {},
   "source": [
    "How do these features combine? Again features add together linearly, so in the common scenario of emission lines and continuum together, we should hear a combination of tone and noise.\n",
    "\n",
    "However we have to note that there is a lot of integrated power in the continuum vs the noise, so a low level of continuum can still dominate the sound, unless we process the spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78555fb4-6c75-4193-84ab-5c35a0d3540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec10 = spec6*1e-3\n",
    "spec10[spec10.size//2] = 1\n",
    "\n",
    "spec11 = spec6*1e-2\n",
    "spec11[spec10.size//2] = 1\n",
    "\n",
    "spec12 = spec6*0.1\n",
    "spec12[spec10.size//2] = 1\n",
    "\n",
    "specs4 = (spec10, spec11, spec12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6903dd-b363-4e0e-a44f-fa56de68649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.modify_preset({'min_freq':100, 'max_freq':2000})\n",
    "\n",
    "for s in specs4:\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "        \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138ca5e-6069-405c-9971-fcabb487318a",
   "metadata": {},
   "source": [
    "Hear that noise is audible, even at less than a 1000th level of the peak. In the 1/10 level continuum the tone is barely audible.  This is because the integrated power in a continuum can overwhelm a very narrow line, even at a low normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac917e9-d34a-4bf4-9e37-bb113a99f324",
   "metadata": {},
   "source": [
    "Processing the continuum in some way before listening can help this scenario. If we want to boost the tone, we could either:\n",
    "- fit and subtract a continuum to focus on the line alone\n",
    "- boost high powers more dramatically i.e. make the spectrum _\"peakier\"_ or _\"cuspier\"_\n",
    "\n",
    "Interestingly (ahem) this is the opposite problem we often have with raw imaging data - we often need to reduce the dynamic range to bring out low surface brightness features so we don't just have a few bright pixels. This can be done by using e.g. a log scale or a positive fractional power (e.g. `img**0.5`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9d4d2-f624-4c78-b8df-993b5f03e683",
   "metadata": {},
   "source": [
    "![image](images/intro_galanalogy.png)\n",
    "_Reducing the dynamic range can help bring out features in astronomical imaging. For spectral audification, we often want to do the opposite_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a7941-e88e-48e5-a9c1-6ccce663332d",
   "metadata": {},
   "source": [
    "In the case of this spectra problem, we want to boost the dynamic range, which can be acheived using a power > 1, for example, a power of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4200e-9197-4dd9-8139-234f93e616c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "power = 2\n",
    "\n",
    "for s in specs4:\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[pow(s, power)], \n",
    "                      'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "        \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84927d8-e8cd-4159-ab85-2c7b84251d16",
   "metadata": {},
   "source": [
    "### 7. Examples: Multiple Emission Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea4340-f389-43fa-9814-b961dbbd9bbe",
   "metadata": {},
   "source": [
    "Finally we'll hear these for multiple emission lines at ones. Again these combine linearly and we hear their independent tones at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ebf83-0b01-488b-8779-6a65823d7027",
   "metadata": {},
   "source": [
    "We'll also make each added line weaker each time to show how we har lines of differing strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77094048-bd06-48f3-89e9-f5851cbc0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "choice = np.random.choice(spec13.size, size=3, replace=False).astype(int)\n",
    "spec13 = spec2.copy()\n",
    "spec14 = spec2.copy()\n",
    "spec15 = spec2.copy()\n",
    "\n",
    "spec13[choice[:1]] = (np.arange(1.)+2)**-2\n",
    "spec14[choice[:2]] = (np.arange(2.)+2)**-2\n",
    "spec15[choice] = (np.arange(3.)+2)**-2\n",
    "\n",
    "specs5 = (spec2, spec13, spec14, spec15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac437df2-00c3-4dd6-8d43-b5f5daa33704",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.modify_preset({'min_freq':100, 'max_freq':800})\n",
    "\n",
    "for s in specs5:\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "        \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.show()\n",
    "    soni.notebook_display(show_waveform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75293df5-3a98-44bc-a111-83536292c2a5",
   "metadata": {},
   "source": [
    "Notice how we can hear even the low final tone clearly despite its low level, while the third line is a bit harder to hear distinctly as it's close to the first line. However close lines often instead manifest as a 'beating': a rapid oscillation in the volume of the tone induced by two close together tones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53f353-90d1-4e74-afab-e91fd4db05ac",
   "metadata": {},
   "source": [
    "### Extra: Make figures we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159ab9c-d403-4206-8cad-cf9bbf313e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches, pyplot as plt\n",
    "flg = 1\n",
    "for s in (specs[0], specs5[0], specs[0]+specs5[0], specs4[-1]):\n",
    "    print('='*100)\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict({'spectrum':[s], 'pitch':[1]})\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, 'mono')\n",
    "    soni.render()\n",
    "        \n",
    "    plot_spec2sound(freqs, s, soni)\n",
    "    plt.savefig(f\"images/intro_{flg}.png\")\n",
    "    plt.show()\n",
    "    flg += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
